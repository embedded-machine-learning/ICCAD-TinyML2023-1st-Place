{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example copies a lot from [a pytorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# To be able to import model\n",
    "sys.path.append('/'+'/'.join(os.getcwd().split('/')[:-1])+'/')\n",
    "\n",
    "from model.Conversion import Start,Stop\n",
    "from model.activations import ReLU,PACT\n",
    "from model.linear import Linear\n",
    "from model.wrapped import FlattenM,MaxPool2d,Dropout\n",
    "from model.blocks import ConvBnA,LinBnA\n",
    "from model.sequential import Sequential\n",
    "from model.Quantizer import LinQuantExpScale\n",
    "from model.QuantizationMethods.MinMSE import MinMSE_convolution_weight_quantization, MinMSE_linear_weight_quantization\n",
    "\n",
    "from model.DataWrapper import DataWrapper\n",
    "from model.convolution.weight_quantization import LinQuantWeight\n",
    "from model.Quantizer import FakeQuant, Quant\n",
    "from model.logger import logger_init, logger_forward\n",
    "from types import FunctionType\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = 'cifa10_vgg_custom_act_weightqaunt_rescaler'\n",
    "\n",
    "\n",
    "if not os.path.exists('./runs'):\n",
    "    os.mkdir('./runs')\n",
    "if not os.path.exists(f'./runs/{path}'):\n",
    "    os.mkdir(f'./runs/{path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (.3, .3, .3))])\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (.3, .3, .3))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is a fixpoint quantization\n",
    "class CustomConvWeightQuant(LinQuantWeight):\n",
    "    @logger_init\n",
    "    def __init__(self, bits: int = 8, size: tuple = (-1,), rounding_mode: str = \"round\", layer_wise=False) -> None:\n",
    "        super(CustomConvWeightQuant,self).__init__(bits, size, rounding_mode,layer_wise)\n",
    "\n",
    "        # self min and max is set to -2**(bits-1) and 2**(bits-1)-1\n",
    "\n",
    "        weight_range = 1\n",
    "        nn.init.constant_(self.delta_in,2*weight_range / (2.0**self.bits - 1))\n",
    "        self.delta_out = self.delta_in\n",
    "\n",
    "    @logger_forward\n",
    "    def forward(self, x: Tensor, rexp_mean: Tensor, rexp_diff: Tensor, fact_fun: FunctionType) -> Tensor:\n",
    "        with torch.no_grad():\n",
    "            fact = fact_fun((self.delta_out.view(1,-1,1,1) * rexp_mean).log2()).view(-1, 1, 1, 1)\n",
    "\n",
    "            self.delta_for_quant = self.delta_in.div(rexp_diff.view(*self.rexp_view)).div_(fact)\n",
    "\n",
    "            # clipping the weights, improves performance\n",
    "            x.data.clamp_(self.delta_for_quant*(self.min-0.5),\n",
    "                        self.delta_for_quant*(self.max+0.5))\n",
    "\n",
    "        return FakeQuant(\n",
    "                x=x.clone(),\n",
    "                delta_in=self.delta_for_quant,\n",
    "                delta_out=self.delta_for_quant,\n",
    "                training=self.training,\n",
    "                min_quant=self.min,\n",
    "                max_quant=self.max,\n",
    "                rounding_mode=self.rounding_mode,\n",
    "            )\n",
    "\n",
    "\n",
    "# custom back propagation for relu6\n",
    "class RELU6_back_function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, val: Tensor, m: Tensor) -> Tensor:\n",
    "        ctx.save_for_backward(val >= m, val >= 0)\n",
    "        return val.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        m_cmp, zero_cmp = ctx.saved_tensors\n",
    "        val_gard = grad_outputs * torch.logical_and(zero_cmp,~m_cmp)\n",
    "        return val_gard, None\n",
    "\n",
    "\n",
    "#custom RELU6 activation function\n",
    "class CustomActivationRelu6(Quant):\n",
    "    def __init__(self, bits, size=(-1,), rounding_mode: str = \"floor\", use_enforced_quant_level: bool = False):\n",
    "        super(CustomActivationRelu6, self).__init__(bits, size, rounding_mode, use_enforced_quant_level)\n",
    "        self.bits = bits\n",
    "        \n",
    "        nn.init.constant_(self.delta_in,6/(2**bits - 1))\n",
    "        self.delta_out = self.delta_in\n",
    "\n",
    "        nn.init.constant_(self.min, 0)\n",
    "        nn.init.constant_(self.max, 2**bits - 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, fake: bool = False, metadata: Optional[DataWrapper] = None,*args,**kargs):\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                if self.use_enforced_quant_level and metadata is not None:\n",
    "                    self.use_quant(metadata)\n",
    "                if self.use_enforced_quant_level and metadata is None:\n",
    "                    raise ValueError(\"Quantization function desired but metadata not passed\")\n",
    "\n",
    "            x = RELU6_back_function.apply(x,6)\n",
    "        return super(CustomActivationRelu6,self).forward(x, fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross layer rescaler definition \n",
    "count = 0\n",
    "ns = []\n",
    "def fun():\n",
    "    points = 1\n",
    "    qa = torch.tensor([q/(points+1) for q in list(range(1,points+1))],device='cuda')\n",
    "    print(qa)\n",
    "    global count \n",
    "    global ns\n",
    "    def calculate_n_a_fixed(weight,mean,var,out_quant,rexp,):\n",
    "        with torch.no_grad():\n",
    "            n = torch.log2(weight.abs() / (out_quant * torch.sqrt(var + 1e-5)))\n",
    "            n = torch.nan_to_num(n,nan=0,posinf=0,neginf=-32).add(rexp.view(-1)).clip(min=-32,max=0)\n",
    "            if count+1>len(ns):\n",
    "                ns.append(n.detach().clone().view(-1))\n",
    "                nr = n.median() * torch.ones_like(n)\n",
    "                nr = torch.ceil(nr)\n",
    "            else:\n",
    "                ns[count] = n.detach().clone().view(-1)\n",
    "                data_points = torch.concat(ns).quantile(qa)\n",
    "                nr = data_points[0] * torch.ones_like(n)\n",
    "                dist = torch.abs(n-data_points[0])\n",
    "                for i in range(1,points):\n",
    "                    nr = torch.where(torch.abs(n-data_points[i]) > dist,nr,data_points[i])\n",
    "                    dist = torch.where(torch.abs(n-data_points[i]) > dist,dist,torch.abs(n-data_points[i]))\n",
    "                nr = torch.ceil(nr)\n",
    "\n",
    "            alpha = (torch.sign(weight)+1e-5).sign() * torch.exp2(n - nr)\n",
    "            return nr, alpha\n",
    "    count += 1\n",
    "    return calculate_n_a_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "weight_quant = CustomConvWeightQuant\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Start and Stop modules convert the Float values to the fake quantized domain\n",
    "        # and during inference to the integer domain expressed by a float (necessary due to NVIDIA)\n",
    "        self.start = Start(bits=8,size=(1,3,1,1),mode=\"auto\",auto_runs=2)\n",
    "        # mode=\"auto\" simply measures min and max of the input and quantized to them in a symmetric manner \n",
    "        self.stop = Stop(size=(1,10))\n",
    "        \n",
    "        self.seq = Sequential(\n",
    "            ConvBnA(  3, 64,3,1,1,activation=CustomActivationRelu6,weight_quant=weight_quant),\n",
    "            ConvBnA( 64, 64,3,1,1,activation=CustomActivationRelu6,weight_quant=weight_quant,BN_shift_alpha_function=fun()),\n",
    "            MaxPool2d(2,2),\n",
    "            Dropout(0.1),\n",
    "            ConvBnA( 64,128,3,1,1,activation=CustomActivationRelu6,weight_quant=weight_quant,BN_shift_alpha_function=fun()),\n",
    "            ConvBnA(128,128,3,1,1,activation=CustomActivationRelu6,weight_quant=weight_quant,BN_shift_alpha_function=fun()),\n",
    "            MaxPool2d(2,2),\n",
    "            Dropout(0.1),\n",
    "            ConvBnA(128,256,3,1,1,activation=CustomActivationRelu6,weight_quant=weight_quant,BN_shift_alpha_function=fun()),\n",
    "            ConvBnA(256,256,3,1,1,activation=CustomActivationRelu6,weight_quant=weight_quant,BN_shift_alpha_function=fun()),\n",
    "            Dropout(0.1),\n",
    "            MaxPool2d(2,2),\n",
    "            FlattenM(1),\n",
    "            LinBnA(256*4*4,10,weight_quant=MinMSE_linear_weight_quantization,weight_quant_channel_wise=True,activation=LinQuantExpScale,affine=False,BN_shift_alpha_function=fun()),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.start(x)\n",
    "        x = self.seq(x)\n",
    "        x = self.stop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example copies a lot from [a pytorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, pr=True):\n",
    "    global testloader,device\n",
    "    global best\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device,non_blocking=True)\n",
    "            labels = labels.to(device,non_blocking=True)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # loss = criterion(outputs, target)\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    net.train()\n",
    "    if pr:\n",
    "        print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:4.1f} %')\n",
    "    if best < 100 * correct / total:\n",
    "        best = 100 * correct / total\n",
    "\n",
    "    return 100 * correct / total, best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000], device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0')\n",
      "tensor([0.5000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9,weight_decay=5e-4)\n",
    "sched= optim.lr_scheduler.CosineAnnealingLR(optimizer,epochs,1e-5,verbose=False)\n",
    "\n",
    "best = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:17<00:00, 35.57it/s, loss=1.65, acc=0.487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce autorun by 1: 1 min/max -1.6666666269302368 / 1.6666666269302368\n",
      "[  1,   625] loss: 131.604,Train Acc: 38.9, Test Acc:50.9%, Best test Acc:50.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.35it/s, loss=1.4, acc=0.629] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce autorun by 1: 0 min/max -1.6666666269302368 / 1.6666666269302368\n",
      "[  2,   625] loss: 111.977,Train Acc: 50.3, Test Acc:60.5%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 38.92it/s, loss=1.33, acc=0.671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3,   625] loss: 106.010,Train Acc: 53.7, Test Acc:46.0%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.29it/s, loss=1.3, acc=0.683] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4,   625] loss: 104.373,Train Acc: 54.7, Test Acc:46.2%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.36it/s, loss=1.4, acc=0.631] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5,   625] loss: 111.888,Train Acc: 50.5, Test Acc:47.0%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.58it/s, loss=1.41, acc=0.623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6,   625] loss: 112.948,Train Acc: 49.8, Test Acc:34.7%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.07it/s, loss=1.41, acc=0.627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7,   625] loss: 112.422,Train Acc: 50.1, Test Acc:22.7%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.75it/s, loss=1.41, acc=0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8,   625] loss: 112.571,Train Acc: 50.0, Test Acc:35.9%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.18it/s, loss=1.41, acc=0.623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9,   625] loss: 112.459,Train Acc: 49.9, Test Acc:29.9%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.12it/s, loss=1.42, acc=0.614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10,   625] loss: 113.956,Train Acc: 49.2, Test Acc:32.7%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.87it/s, loss=1.43, acc=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11,   625] loss: 114.548,Train Acc: 49.0, Test Acc:24.1%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:16<00:00, 37.68it/s, loss=1.45, acc=0.605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12,   625] loss: 115.791,Train Acc: 48.4, Test Acc:23.5%, Best test Acc:60.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 509/625 [00:13<00:03, 38.34it/s, loss=1.44, acc=0.605]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    training_running_correct = 0\n",
    "    with tqdm(enumerate(trainloader, 0),total=len(trainloader),disable=False) as t:\n",
    "        for i, (data,target) in t:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            target = target.to(device,non_blocking=True)\n",
    "            data = data.to(device,non_blocking=True)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad(True)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.sort(outputs.data.clone().detach(), 1,descending=True)\n",
    "            training_running_correct += (preds[:,0].view(-1,1) == target.view(-1,1)).any(dim=1).sum().detach().item()\n",
    "            t.set_postfix({'loss': running_loss/(i+1),'acc':training_running_correct/((i+1)*batch_size)})\n",
    "    ev = eval(net,pr=False)\n",
    "    print(f'[{epoch + 1:3d}, {i + 1:5d}] loss: {running_loss*batch_size/len(trainloader):6.3f},Train Acc: {training_running_correct/len(trainloader):3.1f}, Test Acc:{ev[0]:3.1f}%, Best test Acc:{ev[1]:3.1f}%')\n",
    "    running_loss = 0.0\n",
    "    torch.save(net.state_dict(),f\"./runs/{path}/ckp.pt\")\n",
    "    sched.step()\n",
    "            \n",
    "print('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
